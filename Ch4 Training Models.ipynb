{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color=#000000 size=5>Linear Regression</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[notes] 2 ways to train a lin reg model:  \n",
    "1. normal equation (a closed form equation)  \n",
    "2. gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[notes] brief intro to lin reg  \n",
    "More generally, a linear model makes a prediction by simply computing a **weighted sum** of the input features, plus a constant called the **bias term** (also called the **intercept term**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[model]  \n",
    "$\\hat y = \\theta_0 + \\theta_1 x_1 + \\theta_2 x_2 + \\dots + \\theta_n x_n$  \n",
    "or  \n",
    "$\\hat y = h_{\\boldsymbol \\theta}(\\boldsymbol X) = {\\boldsymbol \\theta}^T \\cdot \\boldsymbol X$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[equation] MSE cost function for a Linear Regression model  \n",
    "$MSE(\\boldsymbol X, h_{\\boldsymbol \\theta}) = MSE(\\boldsymbol \\theta) = \\frac{1}{m}\\sum^m_{i = 1}({\\boldsymbol \\theta}^T \\cdot \\boldsymbol x^{(i)} - y^{(i)})^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color=#000000 size=4>The Normal Equation</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[notes] a closed form solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[equation] Normal Equation  \n",
    "$\\boldsymbol {\\hat \\theta} = ({\\boldsymbol X}^T \\cdot \\boldsymbol X)^{-1} \\cdot {\\boldsymbol X}^T \\cdot \\boldsymbol y$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[implementation] test the equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate some linear-looking data\n",
    "import numpy as np\n",
    "\n",
    "X = 2 * np.random.rand(100, 1)  # rand(shape)\n",
    "y = 4 + 3 * X + np.random.randn(100, 1)  # + np.random.rand(shape): Gaussian noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# (plot)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.plot(X, y, \".\")\n",
    "plt.axis([0, 2, 0, 15])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add x_0 = 1 to each instance\n",
    "X_b = np.c_[np.ones(X.shape), X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the optimal theta\n",
    "theta_best = np.linalg.inv(X_b.T.dot(X_b)).dot(X_b.T).dot(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.0765377 ],\n",
       "       [3.01706651]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see the results\n",
    "theta_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.0765377 ],\n",
       "       [10.11067071]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make predictions with the calculated theta\n",
    "X_new = np.array([[0], [2]])\n",
    "X_new_b = np.c_[np.ones((2, 1)), X_new]  # add x_0 = 1 to each instance\n",
    "\n",
    "y_predict = X_new_b.dot(theta_best)\n",
    "y_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[equation] ${\\boldsymbol y}_{predict} = \\boldsymbol{\\hat X}_{predict} \\cdot \\boldsymbol \\theta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the predictions\n",
    "plt.plot(X_new, y_predict, \"r-\")\n",
    "plt.plot(X, y, \"b.\")\n",
    "plt.axis([0, 2, 0, 15])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[sklearn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "         normalize=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# train a lin reg model\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([4.0765377]), array([[3.01706651]]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# intercept and coefficients\n",
    "lin_reg.intercept_, lin_reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.0765377 ],\n",
       "       [10.11067071]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict\n",
    "\n",
    "lin_reg.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color=#000000 size=4>Computational Complexity</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[notes]  \n",
    "disadvantages:  \n",
    "1. The Normal Equation gets very slow when the number of **features** grows large. (${\\boldsymbol X}^T \\cdot \\boldsymbol X$: an $n \\cdot n$ matrix)\n",
    "  \n",
    "advantages:  \n",
    "1.  linear with regards to **the number of instances** in the training set (it is $O(m)$), so it handles large training sets efficiently, provided they can fit in memory.  <font color=red># why linear?</font>\n",
    "2. **predictions are very fast**:  the computational complexity is linear with regards to both the number of instances you want to make predictions on and the number of features.  <font color=red>#why linear?</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color=#000000 size=5>Gradient Descent</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[notes]  \n",
    "advantages:  \n",
    "1. **a large number of features**  \n",
    "2. when **too many instances to fit in memory**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[notes] random init  \n",
    "start by filling θ with random values (this is called random initialization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[notes] the learning rate  \n",
    "If the learning rate is **too small**, then the algorithm will have to go through many iterations to converge, which will take a long time.  \n",
    "  \n",
    "If the learning rate is **too high**, you might jump across the valley and end up on the other side, possibly even higher up than you were before. This might make the algorithm diverge, with larger and larger values, failing to find a good solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[notes] two challenges  \n",
    "1. converge to a **local minimum**, which is not as good as the global minimum.  \n",
    "2. take a very **long time to cross the plateau**, and if you stop too early you will never reach the global minimum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./img/Figure4_6.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[notes] \n",
    "Fortunately, the **MSE cost function for a Linear Regression model**:  \n",
    "1. **convex function**, which means that if you pick any two points on the curve, the line segment joining them never crosses the curve. This implies that there are no local minima, just one global minimum.  \n",
    "2. It is also a **continuous function** with a slope that never changes abruptly.  \n",
    "  \n",
    "These two facts have a great consequence: Gradient Descent is **guaranteed to approach arbitrarily close the global minimum (if you wait long\n",
    "enough and if the learning rate is not too high)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[notes] standardization\n",
    "  \n",
    "the figure below shows Gradient Descent on a training set where features 1 and 2 have the same scale (on the left), and on a training set\n",
    "where feature 1 has much smaller values than feature 2 (on the right). \n",
    "  \n",
    "Since feature 1 is smaller, it takes a larger change in $\\theta_1$ to affect the cost function, which is why the bowl is elongated along the $\\theta_1$ axis.  <font color=red># why larger change?</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./img/Figure4_7.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[notes] **standardization** is needed when using gradient descent  \n",
    "When using Gradient Descent, you should ensure that all features have a **similar scale** (e.g., using Scikit-Learn’s StandardScaler class), or else it will take much longer to converge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color=#000000 size=4>Batch Gradient Descent</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[notes] def  \n",
    "To implement Gradient Descent, you need to compute the gradient of the cost function with regards to **each** model parameter $\\theta_j$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[equation]  \n",
    "Partial derivatives of the cost function  \n",
    "$\\frac{\\partial}{\\partial \\theta_j}MSE(\\boldsymbol \\theta) = \\frac{2}{m}\\sum^m_{i=1}({\\boldsymbol \\theta}^T \\cdot {\\boldsymbol x}^{(i)}- y^{(i)})x^{(i)}_j$  \n",
    "  \n",
    "Gradient vector of the cost function  \n",
    "  \n",
    "\n",
    "$\n",
    "\\begin{aligned}\n",
    "\\nabla_{\\boldsymbol \\theta}MSE(\\boldsymbol \\theta) = \n",
    "\\begin{bmatrix}\n",
    "\\frac{\\partial}{\\partial \\theta_0}MSE(\\boldsymbol \\theta) \\\\\n",
    "\\frac{\\partial}{\\partial \\theta_1}MSE(\\boldsymbol \\theta) \\\\\n",
    "\\vdots \\\\\n",
    "\\frac{\\partial}{\\partial \\theta_n}MSE(\\boldsymbol \\theta)\n",
    "\\end{bmatrix}\n",
    "= \\frac{2}{m}{\\boldsymbol X}^T \\cdot (\\boldsymbol X \\cdot \\boldsymbol \\theta - \\boldsymbol y)\n",
    "\\end{aligned}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[notes] the whole batch  \n",
    "it uses the **whole** batch of training data at every step. \n",
    "  \n",
    "disadvantages:  \n",
    "1.  it is terribly **slow** on very **large training sets**  \n",
    "  \n",
    "advantages:  \n",
    "1. Gradient Descent **scales well with the number of features**; training a Linear Regression model when there are hundreds of thousands of features is much faster using Gradient Descent than using the Normal Equation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[equation] Gradient Descent step  \n",
    "${\\boldsymbol \\theta}^{(next step)} = \\boldsymbol \\theta - \\eta \\nabla_{\\boldsymbol \\theta}MSE(\\boldsymbol \\theta)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[implementation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.0765377 ],\n",
       "       [3.01706651]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hyperparameters of BGD\n",
    "eta = 0.1  # learning rate\n",
    "n_iterations = 1000  # number of iterations\n",
    "\n",
    "m = 100  # data size\n",
    "\n",
    "theta = np.random.randn(2, 1)  # random init\n",
    "\n",
    "# iteration\n",
    "for iteration in range(n_iterations):\n",
    "    gradients = 2 / m * X_b.T.dot(X_b.dot(theta) - y)\n",
    "    theta = theta - eta * gradients\n",
    "    \n",
    "# check theta\n",
    "theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[notes] difference btw rand() and randn(): [numpy.random.randn()与rand()的区别](https://blog.csdn.net/u010758410/article/details/71799142)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[notes] find a good learning rate and set the number of iterations    \n",
    "To **find a good learning rate**, you can use **grid search**. However, you may want to limit the number of iterations so that grid search can eliminate models that take too long to converge.  \n",
    "  \n",
    "You may wonder **how to set the number of iterations**. If it is too low, you will still be far away from the optimal solution when the algorithm stops, but if it is too high, you will waste time while the model parameters do not change anymore. **A simple solution is to set a very large number of iterations but to interrupt the algorithm when the gradient vector becomes tiny**—that is, when its norm becomes smaller than a tiny number ϵ (called the tolerance)—because this happens when Gradient Descent has\n",
    "(almost) reached the minimum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[notes] convergence rate  \n",
    "When the cost function is convex and its slope does not change abruptly (as is the case for the MSE cost function), it can be shown that Batch Gradient Descent **with a fixed learning rate** has a convergence rate of $O(\\frac{1}{iterations})$. In other words, if you divide the tolerance $\\epsilon$ by 10 (to have a more precise solution), then the algorithm will have to run about 10 times more iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color=#000000 size=4>Stochastic Gradient Descent</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[notes] def  \n",
    "Stochastic Gradient Descent just picks a random instance in the training set at every step and computes the gradients based only on that single instance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[notes]  \n",
    "advantages:  \n",
    "1. this makes the algorithm much **faster** since it has very little data to manipulate at every iteration.  \n",
    "2. It also makes it possible to **train on huge training sets**, since only one instance needs to be in memory at each iteration (SGD can be implemented as an out-of-core algorithm)  \n",
    "3.When **the cost function is very irregular**, this can actually help the algorithm **jump out of local minima**, so Stochastic Gradient Descent has a better chance of finding the global minimum than Batch Gradient Descent does.  \n",
    "  \n",
    "disadvantages:  \n",
    "1. this algorithm is **much less regular** than Batch Gradient Descent: instead of gently decreasing until it reaches the minimum, the cost function will bounce up and down, **decreasing only on average**. Over time it will end up very close to the minimum, but once it gets there it will continue to bounce around, never settling down (see Figure 4-9). **So once the algorithm stops, the final parameter values are good, but not optimal.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[notes] one sulution to the dilemma that the algorithm never settles at the mininum  \n",
    "One solution is to **gradually reduce the learning rate**. The steps **start out large** (which **helps make quick progress** and **escape local minima**), then **get smaller and smaller**, **allowing the\n",
    "algorithm to settle at the global minimum.**    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[notes] learning schedule  \n",
    "**The function that determines the learning rate at each iteration** is called **the learning schedule**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[notes] trade-off of the reducing speed of the learning rate  \n",
    "**If the learning rate is reduced too quickly, you may get stuck in a local minimum, or even end up frozen halfway to the minimum. If the learning rate is reduced too slowly, you may jump around the minimum for a long time and end up with a suboptimal solution if you halt training too early.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[implementation] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.07890078],\n",
       "       [3.0177272 ]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hyperparameters of SGD\n",
    "n_epochs = 50\n",
    "t0, t1 = 5, 50  # learning schedule hyperparameters\n",
    "\n",
    "# learning schedule\n",
    "def learning_schedule(t):\n",
    "    return t0 / (t + t1)\n",
    "\n",
    "# random init\n",
    "theta = np.random.randn(2, 1)\n",
    "\n",
    "# iteration\n",
    "for epoch in range(n_epochs):\n",
    "    for i in range(m):\n",
    "        # randomly select an instance\n",
    "        random_index = np.random.randint(m)\n",
    "        xi = X_b[random_index:random_index + 1]\n",
    "        yi = y[random_index:random_index + 1]\n",
    "        \n",
    "        gradients = 2 * xi.T.dot(xi.dot(theta) - yi)  # not needed to / m\n",
    "        eta = learning_schedule(epoch * m + i)\n",
    "        theta = theta - eta * gradients\n",
    "\n",
    "# check theta\n",
    "theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[notes] why (epoch * m + i)?  \n",
    "\n",
    "when epoch = 0:  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;t = 0, 1, ..., m - 1  \n",
    "  \n",
    "when epoch = 1:  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;t = m, m + 1, ..., 2m - 1  \n",
    "  \n",
    "thus the learning rate reduces gradually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[notes] BGD vs SGD\n",
    "in the example above,  \n",
    "BSG iterates the **whole** set for **1000** times to update theta for 1000 times.  \n",
    "SGD iterates the **whole** set for **50** times to update theta for 50 * 100 = 5000 times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[notes] shuffle the training set to make each instance processed in each epoch\n",
    "Note that since instances are picked randomly, some instances may be picked several times per epoch while others may not be picked at all. If you want to be sure that the algorithm **goes through every instance at each epoch**, another approach is to **shuffle the training set, then go through it instance by instance, then shuffle it again (to guarantee random selection), and so on. However, this generally converges more slowly.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[sklearn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
       "       eta0=0.1, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='invscaling', loss='squared_loss', max_iter=None,\n",
       "       n_iter=50, n_iter_no_change=5, penalty=None, power_t=0.25,\n",
       "       random_state=None, shuffle=True, tol=None, validation_fraction=0.1,\n",
       "       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "# train a sgd reg model\n",
    "sgd_reg = SGDRegressor(n_iter=50, penalty=None, eta0=0.1)  # 50 epochs\n",
    "sgd_reg.fit(X, y.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([4.02886716]), array([2.97221286]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# intercept and coefficients\n",
    "sgd_reg.intercept_, sgd_reg.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color=#000000 size=4>Mini-batch Gradient Descent</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[notes] def  \n",
    "at each step, instead of computing the gradients based on the full training set (as in Batch GD) or based on just one instance (as in Stochastic GD), Mini-batch GD computes the gradients on small random sets of instances called minibatches. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[notes]  \n",
    "advantages:  \n",
    "1. The main advantage of Mini-batch GD over Stochastic GD is that you can get a performance boost from hardware optimization of matrix operations, especially when using GPUs.  \n",
    "2. The algorithm’s progress in parameter space is **less erratic** than with SGD, especially **with fairly large mini-batches**. As a result, Mini-batch GD will end up walking around a bit **closer to the minimum than SGD.**  \n",
    "  \n",
    "disadvantages:  \n",
    "1.  it may be **harder** for it to **escape from local minima**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color=#000000 size=5>Polynomial Regression</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[notes] you can actually use a linear model to fit nonlinear data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[notes] for a quadratic function:  \n",
    "add the square (2nd-degree polynomial) of **each feature** in the training set as new features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[sklearn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate some nonlinear data\n",
    "m = 100\n",
    "X = 6 * np.random.rand(m, 1) - 3\n",
    "y = 0.5 * X ** 2 + X + 2 + np.random.randn(m, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAFPRJREFUeJzt3X2MHdV5x/Hfs2sIL0mEC9uWGGODIKgUtSWsiKtUUSKgNS2K0xdUXpLSNpEVNWmgbdQQIoFKhdqqTURUoaoW0BKJF0WYiIhCY5KCEqTaYdelxWAcLKtrDG5YwCghiWrW+/SPvTe9vtyXufN2zpz5fiTLe6/v7pxZz/zmzDNnzpi7CwDQfFOhGwAAKAeBDgCJINABIBEEOgAkgkAHgEQQ6ACQCAIdABJBoANAIgh0AEjEqjoXdsopp/j69evrXCQANN78/Pwr7j4z7nO1Bvr69es1NzdX5yIBoPHMbCHL5yi5AEAiCHQASASBDgCJINABIBEEOgAkgkAHgEQQ6ABQofmFQ7rtsb2aXzhU+bJqHYcOAG0yv3BIV9++XYeXlnXsqind/fENumDd6sqWRw8dACqyfd+rOry0rGWX3lxa1vZ9r1a6PAIdACqy4cyTdeyqKU2bdMyqKW048+RKl0fJBQAqcsG61br74xu0fd+r2nDmyZWWWyQCHQAqdcG61ZUHeRclFwBIBIEOAIkg0AEgEQQ6ACRibKCb2Z1m9rKZ7ep576fM7FEze77zdz0VfwDAUFl66P8saWPfe9dL+qa7ny3pm53XAICAxga6u39L0mt9b2+SdFfn67skfbjkdgEAJpS3hv4z7n5Qkjp//3R5TQIA5FH5RVEz22xmc2Y2t7i4WPXiAKC18gb698zsVEnq/P3ysA+6+xZ3n3X32ZmZmZyLAwCMkzfQvybpms7X10h6sJzmAADyyjJs8V5J/y7pHDM7YGYfk/TXki4xs+clXdJ5DQAIaOzkXO5+5ZB/uqjktgAACuBOUQBIBIEOADnU+azQrJgPHQAmVPezQrOihw4AE6r7WaFZEegAMKG6nxWaFSUXAJhQ3c8KzYpAB4Ac6nxWaFaUXAAgEQQ6ACSCQAeARBDoAJAIAh0AShTyDlJGuQBASULfQUoPHQBKEvoOUgIdQPLqKoOEvoOUkguApNVZBgl9BymBDiBpg8ogVQZtyDtIKbkASFroMkid6KEDSFroMkidCHQAyYtxIq0qUHIBgEQQ6ACQCAIdABJBoANAIgh0AEgEgQ4AJQg5y2IXwxYBoKDQsyx2Feqhm9mfmNkzZrbLzO41s+PKahgANEXoWRa7cge6ma2R9GlJs+5+nqRpSVeU1TAA6BdDWWOQWKYXKFpyWSXpeDN7U9IJkl4q3iQAeKtYyhqDxDK9QO5Ad/cXzezvJO2X9GNJ29x9W2ktA4Aedc+aOKkYphcoUnJZLWmTpDMkvUvSiWb2kQGf22xmc2Y2t7i4mL+lAFotlrJGzMzd832j2eWSNrr7xzqvf0/SBnf/o2HfMzs763Nzc7mWBwDzC4eClzVCMLN5d58d97kiNfT9kjaY2QlaKblcJIm0BlCZGMoaMctdcnH3HZLul7RT0tOdn7WlpHYBACZUaJSLu98k6aaS2gIAKIBb/wEgEQQ6ACSCQAeAkoS+k5XJuQCgBDHcyUoPHQBKEMMEXQQ6AJQghjtZKbkAQAlimKCLQAeAPnmnGAh9JyuBDgA9Yri4mRc1dACVCj2Ub1IxXNzMix46gMrE2NsdV07pXtx8c2m5cdP0EugAKhPbQymyHGBiuLiZF4EOoDKx9XazHmBCX9zMi0AHUJnYeruxHWDKlvuJRXnwxCIAoeUZkhj6SUl1PLEIABqjN5Q/+cGzJvq+2C7sDkOgA0hekVCO7cLuKIxDB9BoWca5FxlbHsMcLVnRQwfQWFl73kUuhsZ2YXcUAh1AY00yDLFIKDdlGCOBDqCxJul5NyWUiyDQAdSurGGAZZdDQg9PLIpAB1CrsocBltXzbtLwxGEY5QKgVrHOZhhruyZBoAOoVZXDAItM1duk4YnDcOs/gNpVUasuo2QSaw2dW/8BRKuKESdl3NHZ9JEwhUouZnaSmd1vZs+Z2W4z++WyGgYAk0ihZFJU0R76lyT9q7v/jpkdK+mEEtoEABNr0h2dVckd6Gb2Tknvl/T7kuTuhyUdLqdZAJouRD266SWToor00M+UtCjpn8zsFyXNS7rW3X9YSssANFbWC5SxXoRsqiI19FWS3iPpH9z9fEk/lHR9/4fMbLOZzZnZ3OLiYoHFAWiKLGO6u6H/hW17dPXt23MNNcTRigT6AUkH3H1H5/X9Wgn4o7j7FnefdffZmZmZAosD0BRZLlCOCv0i48nbLHfJxd3/x8xeMLNz3H2PpIskPVte0wA0VZYLlMMm1krhFvxQio5y+WNJd3dGuOyT9AfFmwSgifrr4d0Q7u159//7oNBv0hOCYlMo0N39KUlj714CkLZBvWpJP3lv1fSU5K6lZT+q1z1oVEqRh1G0HXeKAihsWD289z1Jco3vdTOePD8CHUBhw3rV3femOz30I8ueqdfd9vHkeRHoAAob1qvufU8Sve6KMdsiAEQu62yLzIcOAIkg0AFEhxuL8qGGDiAq3FiUHz10AFFJ4dmeoRDoAKLCgyryo+QCICrcWJQfgQ4gOtxYlA8lFwBRYYRLfvTQAUSDES7F0EMHEI26RrikehZADx1ANOqYOjflswACHUA06hjhkvIDNAh0AFGpeoRLyg/QINABtErK49wJdACtk+o4d0a5AEAiCHQASASBDgCJINABIBEEOgAkgkAHkOyt8G3DsEWg5VK+Fb5t6KEDLccj39JRONDNbNrM/sPMHiqjQQDqxSPf0lFGyeVaSbslvbOEnwWgQvMLh95yy3vKt8K3TaFAN7PTJP2GpFsk/WkpLQJQiVG18lRvhW+boiWXWyX9uaTlEtoCoELUytOXO9DN7DJJL7v7/JjPbTazOTObW1xczLu42jB8C6kaVitnm0+HuXu+bzT7K0kflbQk6Tit1NAfcPePDPue2dlZn5uby7W8OjB8q10G1ZNT17/ObPPNYGbz7j477nO5a+ju/jlJn+ss7AOSPjMqzJsg5SeZ4GhtDbL+WnmRbb6NB8TYcWNRj5SfZIKjcfBekXebb+sBMXalBLq7Py7p8TJ+VkgM32qPuh5GHPu2lHeb54AYJ3rofeoevtWEnT5FVR+8i/Rg694m8mzznM3GiUAPiNPWsKo8eOftwTZlm+BsNk6tnMtl1DCtOodwMS44XXlvp2/SNnHButX65AfPIswj0ogeepmnoKN6QHX3jjhtTVfeHmws2wSlwGaKPtDLDtlRp8J1X+jhtDVteUo6MWwTk+xzBH9cog/0skN2VA8oRO+IOTTQL/Q2kXWfa0q9v02iD/SyQ3ZUDyiG3hEQWtZ9jqGL8cl9638eeW/957QOqFeWfa7bQ+8GPz306lR+63+dQp+CAm2TZZ/rntE+sPOA6usWYpRWDlsEmi6mGRK37jyg+76zX1ffvj2K9rRZI3roZaF0g5DK2v5iuhhJHT0urQn0WHaCUTt1KgecVNajTGVufzGFaCzj5rGiNYEew04Q001NVWnKetR90Clz+4spRBkZFpfWBHoMO0FMNzVVpQnrEeKgU+b2F1uIMmghHq0J9Bh2gthuaqpCE9YjxEGn7O2PEMUgjRiHnhJq6OExfhpNk3UcemMDPfbQKFvZ69u231+/tq8/miWpG4v6jbu4mNqOWnbNtykXLqtUtGQxbjtLcTtE/BoZ6MNqoDEEVRU7ctk13yZcuIzZuO0shu0Q7dTIQB924S10UFW1I5d9obEJFy5j1D1Yv/T6j0duZ6G3w/72cpbQHo0M9GEjBkIHVVU7cv/6StJtj+3NvaPGMOKnaXoP1qumTKump3TkyODtLPR22N9ezhLao5GBLg2ugYYOqip35O76lrWjtnHYW5Eea+/B+siy63cvXKs1Jx0/8GeF3g7720tZrT0aG+jDhAyqOnZkdtR8ih4I+w/Wv/2e00Z+f+gDZgxnCahfcoGeV1n1xqp3ZHbUfIoeCGPodfcat73G1l7Ug0BXs+qN7Kj5rD7hWE2ZSe65D4S90zT0vq5b1u019FkC6kegq3lljN4d9Z4d+/XIroO69LxTddV7Tw/csvFCjLyYXzikmx96Rsvumpoy3XjZz+dadiwH/qZtr6gPga7mljHu2bFfN3z1aUnSt59/RZKiDvVQgdgbgCbXoR8dLvxzQgZpU7dXVC93oJvZWklflvSzkpYlbXH3L5XVsDplKWPEOKb3kV0H3/I65kAPFYhlBWAsQUrZDcMU6aEvSfozd99pZu+QNG9mj7r7syW1rVaj6o2xnGr3u/S8U3/SM+++rkPeg1uoQJwkAEetW0xBSn0cg+QOdHc/KOlg5+sfmNluSWskNTLQR4nlVLtftzdeRg09a0gXObiFDMQsAZhl3QhSxKyUGrqZrZd0vqQdZfy82MRyqj3IVe89vXCZZZKQLmP4X6yBGOuBG8iqcKCb2dslbZV0nbt/f8C/b5a0WZJOPz3e+u4oMZ1qV2GSIKvj4BbqekWoA3eM12fQTIXmQzezYyQ9JOnr7v7FcZ/nARdxmvSBD1VOHRv6ekXd4Rp6fdEMlc+HbmYm6Q5Ju7OEOcLIElB5RvlUdQE5dNmj7pJQ6PVFWoqUXN4n6aOSnjazpzrv3eDuDxdvFoaZ5OLl1p0HdP/8AS0dGR+uZYV00YCK+XpFFdq2vqhWkVEuT0iyEtuCMbIGa/dz//vmsroFtazhOuiAUWeNPfXrFf3atr6oFneKRqpIsHY/1w1zkzKF67ADxiQhXUZAxTwSpgp1rS8XX9NHoEeoaLD2fm56ynT57Fr9Vme611E79bADxqQh3bZAbgIuvrYDgR6hosE67HPjdupRBwxCuhmGHbC5+NoOBHqEygjWQZ8bt1NTz222UQdsLr62A4FeQFU1yUHBWsaysuzU40a7EPZH6/2dSIr2sXMcrNuBQM+p6ppkb7CW+RzRvDs1Ndi3OurB0dNTkruWlj3Y72fcAZuyWfpaEehV9CzrrEmWuay8O3VTarB1nkX0/04kyRXu90MvHMkHelU9yzprkjHUP2Nowzh1n0UcNZqo00M/spz/EXdloBfebskHelU9yzp7QzH0vGJowzh1n0X0/066bYj194P0JR/oVfYs6+wNDVrWoPJClSWH2Ht/Ic4i+n8nMf9+kL5Csy1OKtRsiymOzhhUXpDU+guXKf5fA5XPttgksfcs8xhUXpDUiAuXVUrx/xrIqhWBnqJh5YXYL1yGRO8dqSPQG2rYRcq6L1w2JSQZR482INAbbFB5oc6SQ5GQrPtA0FuiOry0rFu/8V1dd/G7CXUkZSp0A9Bcw+r443QPBF/YtkdX375d8wuHKm7p/5eopkxadumJ51+pbdlAXQh05NYNyWnLNt96V94DQRHdEtX7zjpFpqPv6ARSQckFmQ16rmiemn2ou04vWLda1138bj35369x4RhJasU49FTVWYcu+6JiyIupTbmQC3QxDj1xdY/aKPu2+pDjxRmrjlRRQ2+ouuvQeevlAOpDD72h6q5DN2FyLqDtqKE3GLVgoB2oobcAtWAAvaihA0AiCHQASASBDgCJKBToZrbRzPaY2V4zu76sRgEAJpc70M1sWtJtki6VdK6kK83s3LIaBgCYTJEe+oWS9rr7Pnc/LOk+SZvKaRYAYFJFAn2NpBd6Xh/ovAcACKBIoNuA995yl5KZbTazOTObW1xcLLA4AMAoRQL9gKS1Pa9Pk/RS/4fcfYu7z7r77MzMTIHFoQrzC4d022N7edADkIAid4o+KelsMztD0ouSrpB0VSmtQi14ziaQltw9dHdfkvQpSV+XtFvSV9z9mbIahupNMmMjPXkgfoXmcnH3hyU9XFJbULOsMzbes2O/bnxwl44su952zPiePJOGAWEwOVeLZZkSd37hkG58cJeWlleudx9+c/TDLSjjAOEQ6C03bsbG7fte1XLPFMtTUzZy7vWyn2wEIDvmcsFI3bLMlEmrpkw3bzpvZEDzZCMgHB5wgbEmrYlTQwfKxQMuUJpJH6TBgzeAMCi5AEAiCHQASASBDgCJINABIBEEOgAkgkAHgETUOg7dzBYlLeT89lMkvVJic0JiXeLEusSJdZHWufvY+cdrDfQizGwuy8D6JmBd4sS6xIl1yY6SCwAkgkAHgEQ0KdC3hG5AiViXOLEucWJdMmpMDR0AMFqTeugAgBEaFehm9pdm9l9m9pSZbTOzd4VuU15m9rdm9lxnfb5qZieFblNeZna5mT1jZstm1rjRCGa20cz2mNleM7s+dHuKMLM7zexlM9sVui1FmNlaM3vMzHZ3tq1rQ7epCDM7zsy+Y2b/2Vmfv6hkOU0quZjZO939+52vPy3pXHf/ROBm5WJmvyrp39x9ycz+RpLc/bOBm5WLmf2cpGVJ/yjpM+7emEnvzWxa0nclXSLpgKQnJV3p7s8GbVhOZvZ+SW9I+rK7nxe6PXmZ2amSTnX3nWb2Dknzkj7c4P8Xk3Siu79hZsdIekLSte6+vczlNKqH3g3zjhMlNedo1Mfdt7n7UufldkmnhWxPEe6+2933hG5HThdK2uvu+9z9sKT7JG0K3Kbc3P1bkl4L3Y6i3P2gu+/sfP0DSbslrQnbqvx8xRudl8d0/pSeX40KdEkys1vM7AVJV0u6MXR7SvKHkh4J3YiWWiPphZ7XB9Tg4EiRma2XdL6kHWFbUoyZTZvZU5JelvSou5e+PtEFupl9w8x2DfizSZLc/fPuvlbS3ZI+Fba1o41bl85nPi9pSSvrE60s69JQNuC9xp75pcbM3i5pq6Tr+s7QG8fdj7j7L2nlbPxCMyu9JBbdI+jc/eKMH71H0r9IuqnC5hQybl3M7BpJl0m6yCO/mDHB/0vTHJC0tuf1aZJeCtQW9OjUmrdKutvdHwjdnrK4++tm9rikjZJKvXgdXQ99FDM7u+flhyQ9F6otRZnZRkmflfQhd/9R6Pa02JOSzjazM8zsWElXSPpa4Da1Xuci4h2Sdrv7F0O3pygzm+mOZDOz4yVdrAryq2mjXLZKOkcrIyoWJH3C3V8M26p8zGyvpLdJerXz1vYGj9j5TUl/L2lG0uuSnnL3XwvbquzM7Ncl3SppWtKd7n5L4CblZmb3SvqAVmb1+56km9z9jqCNysHMfkXStyU9rZX9XZJucPeHw7UqPzP7BUl3aWUbm5L0FXe/ufTlNCnQAQDDNarkAgAYjkAHgEQQ6ACQCAIdABJBoANAIgh0AEgEgQ4AiSDQASAR/wehFyZqgniUzAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot\n",
    "plt.plot(X, y, \".\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.27217776]), array([-0.27217776,  0.07408073]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# train a transformer\n",
    "poly_features = PolynomialFeatures(degree=2, include_bias=False)\n",
    "\n",
    "# transform data\n",
    "X_poly = poly_features.fit_transform(X)\n",
    "\n",
    "X[0], X_poly[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "         normalize=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train a model\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_poly, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.91216112]), array([[0.94871831, 0.49908145]]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# intercept and coefficients\n",
    "lin_reg.intercept_, lin_reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot\n",
    "y_predict = lin_reg.predict(X_poly)\n",
    "plt.plot(X, y, \"b+\")\n",
    "plt.plot(X, y_predict, \"r.\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[notes] find relationships  \n",
    "Note that when there are multiple features, Polynomial Regression is capable of finding relationships between features (which is something a plain Linear Regression\n",
    "model cannot do). This is made possible by the fact that PolynomialFeatures also\n",
    "adds all combinations of features up to the given degree. For example, if there were two features a and b, PolynomialFeatures with degree=3 would not only add the\n",
    "features $a^2$, $a^3$, $b^2$, and $b^3$, but also the combinations $ab$, $a^2b$, and $ab^2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[notes] combinatorial explosion  \n",
    "PolynomialFeatures(degree=d) transforms an array containing n features into an array containing $\\frac{(n+d)!}{d!n!}$ features, where n! is the factorial of n, equal to 1 × 2 × 3 × ⋯ × n. Beware of the combinatorial explosion of the number of features!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color=#000000 size=5>Learning Curves</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[notes] high-degree polynomial models are prone to overfit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[notes] decide how complex the model should be an if its underfitting or overfitting\n",
    "in general you won’t know what function generated the data, so how can you decide **how complex** your model should be? How can you tell that your model is **overfitting or underfitting** the data?  \n",
    "  \n",
    "1. cv. If a model performs well on the training data but generalizes poorly according to the cross-validation metrics, then your model is overfitting. If it performs poorly on both, then it is underfitting.   \n",
    "  \n",
    "2. Another way is to look at the learning curves: these are plots of the model’s performance on the training set and the validation set as a function of the training set size. **To generate the plots, simply train the model several times on different sized subsets of the training set.** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[sklearn] generate the learning curves of a lin reg model on the quadratic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def plot_learning_curves(model, X, y):\n",
    "    # split\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)\n",
    "    \n",
    "    train_errors, val_errors = [], []\n",
    "    \n",
    "    for m in range(1, len(X_train)):\n",
    "            # train a model\n",
    "            model.fit(X_train[:m], y_train[:m])\n",
    "            \n",
    "            # predict\n",
    "            y_train_predict = model.predict(X_train[:m])\n",
    "            y_val_predict = model.predict(X_val)\n",
    "            \n",
    "            # append the mse to the list\n",
    "            train_errors.append(mean_squared_error(y_train_predict, y_train[:m]))\n",
    "            val_errors.append(mean_squared_error(y_val_predict, y_val))\n",
    "\n",
    "    # plot\n",
    "    plt.plot(np.sqrt(train_errors), \"r-+\", linewidth=2, label=\"train\")\n",
    "    plt.plot(np.sqrt(val_errors), \"b-\", linewidth=3, label=\"val\")\n",
    "    plt.xlabel(\"Training set size\")\n",
    "    plt.ylabel(\"RMSE\")\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the learning curves of the lin reg model\n",
    "lin_reg = LinearRegression()\n",
    "plot_learning_curves(lin_reg, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[notes] explanation  \n",
    "First, let’s look at the performance on the training data: when there are just one or two instances in the training set, the model can fit them perfectly, which is why the curve starts at zero. But as new instances are added to the training set, it becomes impossible for the model to fit the training data perfectly, **both because the data is noisy and because it is not linear at all.** So the error on the training data goes up until it reaches a plateau, **at which point adding new instances to the training set doesn’t make the average error much better or worse.**  \n",
    "Now let’s look at the performance of the model on the validation data. When the model is trained on very few training instances, it is incapable of generalizing properly, which is why the validation error is initially quite big. Then as the model is shown more training examples, it learns and thus the validation error slowly goes down. However, once again a straight line cannot do a good job modeling the data, so the error ends up at a plateau, very close to the other curve.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[notes] a typical underfitting model  \n",
    "These learning curves are typical of an **underfitting model**. **Both** curves have reached a **plateau**; they are **close and fairly high.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[notes] solutions to a underfitting model  \n",
    "If your model is underfitting the training data, **adding more training examples will not help**. You need to **use a more complex model**\n",
    "or **come up with better features.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[sklearn] the learning curves of a $10^{th}$-degree poly model on the same data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# create a pipeline\n",
    "polynomial_regression = Pipeline((\n",
    "    (\"poly_features\", PolynomialFeatures(degree=10, include_bias=False)),\n",
    "    (\"lin_reg\", LinearRegression())\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot\n",
    "plot_learning_curves(polynomial_regression, X, y)\n",
    "plt.axis([0, 80, 0, 3])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[notes] a typical overfitting model  \n",
    "There is a **gap** between the curves. This means that the model performs significantly better on the training data than on the validation data, which is the hallmark of an **overfitting model**. **However, if you used a much larger training set, the two curves would continue to get closer.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[notes] solutions to a overfitting model\n",
    "One way to improve an overfitting model is to feed it **more training data** until the validation error reaches the training error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[notes] the bias/variance tradeoff\n",
    "An important theoretical result of statistics and Machine Learning is the fact that a model’s generalization error can be expressed as the **sum** of three very different errors:  \n",
    "  \n",
    "**Bias**  \n",
    "This part of the generalization error is due to **wrong assumptions**, such as assuming that the data is linear when it is actually quadratic. A **high-bias** model is most likely to **underfit the training data.**  \n",
    "  \n",
    "**Variance**  \n",
    "This part is due to the model’s **excessive sensitivity to small variations** in the training data. A model with many degrees of freedom (such as a high-degree polynomial model) is likely to have high variance, and thus to **overfit** the training data.  \n",
    "  \n",
    "**Irreducible error**  \n",
    "This part is due to the **noisiness of the data itself**. The only way to reduce this part of the error is to **clean up** the data (e.g., fix the data sources, such as broken sensors, or detect and remove outliers).  \n",
    "  \n",
    "**Increasing a model’s complexity will typically increase its variance and reduce its bias. Conversely, reducing a model’s complexity increases its bias and reduces its variance**. This is why it is called a tradeoff."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color=#000000 size=5>Regularized Linear Models</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[notes]  the fewer degrees of freedom a model has, the harder it will be for it to overfit the data.  \n",
    "  \n",
    "For example, a simple way to regularize a polynomial model is to reduce the number of polynomial degrees.  \n",
    "  \n",
    "For a linear model, regularization is typically achieved by constraining the weights of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color=#000000 size=4>Ridge Regression</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[notes] intro\n",
    "a regularization term equal to $\\alpha \\sum^n_{i = 1}{\\theta_i}^2$ is added to the cost function. This forces the learning algorithm to **not only fit the data but also keep the model weights as small as possible.**  \n",
    "  \n",
    "Note that the regularization term should **only be added to the cost function during training. Once the model is trained, you want to evaluate the model’s performance using the unregularized performance measure.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[notes] reasons for why a cost func used for training is diff from the performance measure for testing  \n",
    "Apart from regularization, another reason why they might be different is that a good training cost function should have **optimization friendly derivatives**, while the performance measure used for testing should be **as close as possible to the final objective.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[notes] about the alpha  \n",
    "If α = 0 then Ridge Regression is just Linear Regression.  \n",
    "If α is very large, then all weights end up very close to zero and the result is a flat line going through the data’s mean.  <font color=red># why mean?</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/Figure4_17.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[equation]  Ridge Regression cost function\n",
    "$J(\\boldsymbol \\theta) = MSE(\\boldsymbol \\theta) + \\alpha\\frac{1}{2}\\sum^n_{i = 1}{\\boldsymbol \\theta_i}^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[notes] the bias term is not regularized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[notes] the vectorized form  \n",
    "If we define $\\boldsymbol w$ as the vector of feature weights ($theta_1$ to $\\theta_n$), then the regularization term is\n",
    "simply equal to $\\frac{1}{2}(||\\boldsymbol w||_2)^2$, where $|| \\cdot ||_2$ represents the ℓ2 norm of the weight vector. For Gradient Descent, just add $\\alpha \\boldsymbol w$ to the MSE gradient vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[notes] scale the data before implementing regularizations  \n",
    "It is important to **scale the data** (e.g., using a StandardScaler) before performing Ridge Regression, as it is sensitive to the scale of the input features. **This is true of most regularized models**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[equation]  Ridge Regression closed-form solution  \n",
    "$\\hat {\\boldsymbol \\theta} = ({\\boldsymbol X}^T \\cdot \\boldsymbol X + \\alpha \\boldsymbol A)^{-1} \\cdot {\\boldsymbol X}^T \\cdot \\boldsymbol y$  <font color=red># derivation?</font>\n",
    "  \n",
    "A is the n × n identity matrix (A square matrix full of 0s except for 1s on the main diagonal (top-left to bottom-right).) except with a 0 in the top-left cell, corresponding to the bias term)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[sklearn] ridge reg with sklearn, using Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=None, solver='cholesky', tol=0.001)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# train a model\n",
    "ridge_reg = Ridge(alpha=1, solver=\"cholesky\")\n",
    "# \"cholesky\" a closed-form solution (a variant of the equation above \n",
    "# using a matrix factorization technique by André-Louis Cholesky):\n",
    "\n",
    "ridge_reg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.89133634]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict\n",
    "ridge_reg.predict([[1.5]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[sklearn] ridge reg with SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
       "       eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='invscaling', loss='squared_loss', max_iter=None,\n",
       "       n_iter=None, n_iter_no_change=5, penalty='l2', power_t=0.25,\n",
       "       random_state=None, shuffle=True, tol=None, validation_fraction=0.1,\n",
       "       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train a model\n",
    "ridge_sgd_reg = SGDRegressor(penalty=\"l2\")\n",
    "ridge_sgd_reg.fit(X, y.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.03568558])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict\n",
    "ridge_sgd_reg.predict([[1.5]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color=#000000 size=4>Lasso Regression</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[equation]  Lasso Regression cost function\n",
    "$J(\\boldsymbol \\theta) = MSE(\\boldsymbol \\theta) + \\alpha \\sum^n_{i = 1}|\\theta_i|$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[notes] feature selection  \n",
    "An important characteristic of Lasso Regression is that it tends to completely eliminate the weights of the least important features (i.e., set them to zero). . For example, the dashed line in the right plot (with α = 10-7) looks quadratic (the actual degree is 10), almost linear: all the weights for the high-degree polynomial features are equal to zero. In other words, Lasso Regression automatically performs feature selection and outputs a sparse model (i.e., with few nonzero feature weights)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/Figure4_18.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[notes] subgradient vector  \n",
    "The Lasso cost function is not differentiable at θi = 0 (for i = 1, 2, ⋯, n), but Gradient Descent still works fine if you use a subgradient vector g (You can think of a subgradient vector at a nondifferentiable point as an intermediate vector between the gradient vectors around that point.) instead when any θi = 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[equation] Lasso Regression subgradient vector  \n",
    "$g(\\boldsymbol \\theta, J) = \\nabla_{\\boldsymbol \\theta} MSE(\\boldsymbol \\theta) + \\alpha\n",
    "\\begin{bmatrix}\n",
    "sign(\\theta_1) \\\\\n",
    "sign(\\theta_2) \\\\\n",
    "\\vdots \\\\\n",
    "sign(\\theta_n) \\\\\n",
    "\\end{bmatrix}\n",
    "where \n",
    "sign(\\theta_i) =\\left\\{\n",
    "\\begin{aligned}\n",
    "-1 & \\quad if\\; \\theta_i < 0 \\\\\n",
    "0 & \\quad if\\; \\theta_i = 0 \\\\\n",
    "+1 & \\quad if\\; \\theta_i > 0\n",
    "\\end{aligned}\n",
    "\\right.\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[sklearn] lasso reg using Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=0.1, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# train a model\n",
    "lasso_reg = Lasso(alpha=0.1)\n",
    "lasso_reg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.84504148])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict\n",
    "lasso_reg.predict([[1.5]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[sklearn] lasso using SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
       "       eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='invscaling', loss='squared_loss', max_iter=None,\n",
       "       n_iter=None, n_iter_no_change=5, penalty='l1', power_t=0.25,\n",
       "       random_state=None, shuffle=True, tol=None, validation_fraction=0.1,\n",
       "       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train a model\n",
    "lasso_sgd_reg = SGDRegressor(penalty=\"l1\")\n",
    "lasso_sgd_reg.fit(X, y.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.0767993])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict\n",
    "lasso_sgd_reg.predict([[1.5]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color=#000000 size=4>Elastic Net</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[notes] intro  \n",
    "Elastic Net is a middle ground between Ridge Regression and Lasso Regression. The\n",
    "regularization term is a simple mix of both Ridge and Lasso’s regularization terms,\n",
    "and you can control the mix ratio r. When **r = 0**, Elastic Net is equivalent to **Ridge Regression**, and when **r = 1**, it is equivalent to **Lasso Regression**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[equation] Elastic Net cost function\n",
    "$J(\\boldsymbol \\theta) = MSE(\\boldsymbol \\theta) + r \\alpha \\sum^n_{i = 1} |\\theta_i| + \\frac{1 - r}{2} \\alpha \\sum^n_{i = 1} {\\theta_i}^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[notes] selection among ridge, lasso and elastic  \n",
    "So when should you use Linear Regression, Ridge, Lasso, or Elastic Net? It is **almost always preferable to have at least a little bit of regularization, so generally you should avoid plain Linear Regression.**  \n",
    "  \n",
    "**Ridge** is a **good default**,   \n",
    "   \n",
    "but if you suspect that **only a few features are actually useful**, you should prefer **Lasso or Elastic Net since they tend to reduce the useless features’weights down to zero** as we have discussed. In general, **Elastic Net is preferred over Lasso** since Lasso may **behave erratically when the number of features is greater than the number of training instances or when several features are strongly correlated.**  <font color=red># why behave erratically?</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[sklearn] elastic net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElasticNet(alpha=0.1, copy_X=True, fit_intercept=True, l1_ratio=0.5,\n",
       "      max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "      random_state=None, selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "# train a model\n",
    "elastic_net = ElasticNet(alpha=0.1, l1_ratio=0.5)  # l1_ratio corresponds to the mix ratio r\n",
    "elastic_net.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.8455854])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict\n",
    "elastic_net.predict([[1.5]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color=#000000 size=4>Early Stopping</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[notes] intro  \n",
    "A very different way to regularize iterative learning algorithms such as Gradient\n",
    "Descent is to stop training as soon as the validation error reaches a minimum. After training for a while the **validation error stops decreasing and actually starts to go back up.** This indicates that the model has started to **overfit*** the training data. With early stopping you just stop training as soon as the validation error reaches the minimum. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[notes] when apply it to SGD and mini-batch GD  \n",
    "With Stochastic and Mini-batch Gradient Descent, the curves are **not so smooth**, and it may be **hard to know whether you have reached the minimum or not.** One solution is to **stop only after the validation error has been above the minimum for some time** (when you are confident that the model will not do any better), then **roll back the model parameters to the point where the validation error was at a minimum.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[sklearn] early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparation\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_train_poly, X_val_poly, y_train_poly, y_val_poly = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# scale\n",
    "std_scaler = StandardScaler()\n",
    "X_train_poly_scaled = std_scaler.fit_transform(X_train_poly)\n",
    "X_val_poly_scaled = std_scaler.fit_transform(X_val_poly)\n",
    "\n",
    "y_train = y_train_poly\n",
    "y_val = y_val_poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Neko\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# early stopping\n",
    "from sklearn.base import clone\n",
    "\n",
    "sgd_reg = SGDRegressor(n_iter=1, warm_start=True, penalty=None, \n",
    "                       learning_rate=\"constant\", eta0=0.0005)  # 1 iter per time\n",
    "\n",
    "minimum_val_error = float(\"inf\")\n",
    "best_epoch = None\n",
    "best_model = None\n",
    "\n",
    "for epoch in range(100):\n",
    "    # train a model\n",
    "    sgd_reg.fit(X_train_poly_scaled, y_train_poly)  # continues where it left off\n",
    "    \n",
    "    # predict\n",
    "    y_val_predict = sgd_reg.predict(X_val_poly_scaled)\n",
    "    \n",
    "    # mse\n",
    "    val_error = mean_squared_error(y_val_predict, y_val)\n",
    "    \n",
    "    # find the optimal\n",
    "    if val_error < minimum_val_error:\n",
    "        minimum_val_error = val_error\n",
    "        best_epoch = epoch\n",
    "        best_model = clone(sgd_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[notes] Note that with warm_start=True, when the fit() method is called, it just continues training where it left off instead of restarting from scratch."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
